
# 📊 Amazon Sales Data Analysis Pipeline

## 🎯 Aim

The aim of this project is to design a **data cleaning and database integration pipeline** using **Python** and **PostgreSQL**. This workflow transforms raw Amazon sales data into structured, reliable information that can be used for **dashboards, trend analysis, and decision-making**.

---

## 📝 Objectives

1. Automate the cleaning of raw sales datasets.
2. Standardize inconsistent column names using **snake_case** for database readiness.
3. Store the cleaned dataset securely into **PostgreSQL**.
4. Create a reproducible workflow that beginners and professionals can adapt.

---

## 🎯 Purpose of Data Analysis

Data analysis enables businesses to:

* Identify **sales trends** by month, category, and geography.
* Track **order fulfillment status** and delivery patterns.
* Monitor **revenue generation** across different SKUs and channels.
* Build **dashboards in Google Sheets, Power BI, or Tableau** using the cleaned PostgreSQL data.

---

## ⚙️ Tech Stack Workflow

* **Python (pandas, sqlalchemy, psycopg2)** → For data cleaning & ETL (Extract, Transform, Load).
* **PostgreSQL** → For structured data storage and querying.

**Workflow:**
`Raw Dataset → Python Cleaning → Save CSV → Load into PostgreSQL → Query & Analyze`

---

## 📂 Dataset Columns

The dataset contains the following attributes:

```
['index', 'order_id', 'date', 'status', 'fulfilment', 'sales_channel',
 'ship_service_level', 'style', 'sku', 'category', 'size', 'asin',
 'courier_status', 'qty', 'currency', 'amount', 'ship_city',
 'ship_state', 'ship_postal_code', 'ship_country', 'month',
 'month_name', 'day', 'monthly_sale_analysis']
```
Dataset Link: https://www.kaggle.com/code/sindhu1304/sql-amazon-sales/notebook
---

## 🚀 Step-by-Step Guide

### Step 1: Install Required Libraries

```bash
pip install pandas sqlalchemy psycopg2-binary
```

---

### Step 2: Clean Raw Data in Python

```python
import pandas as pd

# Load raw dataset
df = pd.read_csv("amazon_sales.csv")

# Convert column names to snake_case
df.columns = (
    df.columns.str.strip()
    .str.lower()
    .str.replace(" ", "_")
    .str.replace("-", "_")
    .str.replace(r"[^\w_]", "", regex=True)
)

# Save cleaned dataset
df.to_csv("clean_amazon_sales.csv", index=False)
print("✅ Cleaned dataset saved as 'clean_amazon_sales.csv'")
```

---

### Step 3: Connect to PostgreSQL & Upload Data

```python
from sqlalchemy import create_engine

# Database credentials
username = "postgres"       # default user
password = "your_password"  # replace with your actual password
host = "localhost"
port = "5432"
database = "amazon_db"

# Create SQLAlchemy engine
engine = create_engine(f"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}")

# Upload DataFrame to PostgreSQL
table_name = "amazon_sales"
df.to_sql(table_name, engine, if_exists="replace", index=False)

print(f"✅ Data inserted into Postgres table '{table_name}' successfully!")
```

---

### Step 4: Verify Data in PostgreSQL

```python
with engine.connect() as conn:
    result = conn.execute(f"SELECT * FROM amazon_sales LIMIT 5;")
    for row in result:
        print(row)
```

---

## 📈 Business Value

* **For Clients:** Provides a clear pipeline to transform messy e-commerce data into structured insights.
* **For Recruiters:** Demonstrates strong **data engineering + SQL integration** capabilities.
* **For Teams:** Reproducible and scalable workflow for any dataset.

---

## ✅ Key Takeaways

* Cleaning data into **snake_case** ensures compatibility with SQL databases.
* Automating ETL with Python reduces manual errors and improves efficiency.
* PostgreSQL provides a strong backbone for further analytics and dashboards.

---

## 📌 Next Steps

* Connect PostgreSQL to **Tableau/Power BI** for interactive dashboards.
* Automate pipeline with **Airflow** or **Prefect**.
* Build APIs to share insights with other applications.

 **Business Insights**

- **Insight:** 50% of revenue from just 4 categories (Set, Kurta, Western Dress, Top).
    
- **Implication:** Portfolio is concentrated — risk if demand shifts.
    
- **Recommendation:** Diversify into underperforming categories (e.g., kidswear, accessories) or double down on top 4 with more SKUs.
    
